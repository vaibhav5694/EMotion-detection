{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "y_kOL2qGD5_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQxnzOrYqWCN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "649fa974-6918-4a2b-cd13-6c12b475fa93"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e7392d9224b0>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Calculate class weights manually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mclass_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mclass_weight_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: compute_class_weight() takes 1 positional argument but 3 were given"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the FER2013 dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/fer2013.csv')\n",
        "\n",
        "# Extract pixel values and labels\n",
        "pixels = data['pixels'].values\n",
        "labels = data['emotion'].values\n",
        "\n",
        "# Convert pixel values to arrays and normalize them\n",
        "pixels = np.array([np.fromstring(pixel, dtype=int, sep=' ') for pixel in pixels])\n",
        "pixels = pixels / 255.0  # Normalize to the range [0, 1]\n",
        "pixels = pixels.reshape(-1, 48, 48, 1)\n",
        "\n",
        "# Convert labels to categorical format\n",
        "labels = to_categorical(labels, num_classes=7)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(pixels, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize test data\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Calculate class weights manually\n",
        "class_labels = np.unique(labels.argmax(axis=1))\n",
        "class_weights = compute_class_weight('balanced', class_labels, labels.argmax(axis=1))\n",
        "class_weight_dict = dict(zip(class_labels, class_weights))\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 15:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * np.exp(-0.1)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with augmented data, class weights, and callbacks\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=64),\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[lr_scheduler, early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Confusion Matrix\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1', '2', '3', '4', '5', '6'], yticklabels=['0', '1', '2', '3', '4', '5', '6'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "# Save the model (optional)\n",
        "model.save('emotion_detection_model.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "\n",
        "# Upload an image file to Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the pre-trained emotion detection model\n",
        "model = load_model('emotion_detection_model.h5')\n",
        "\n",
        "# Map the emotion label to its corresponding emotion\n",
        "emotion_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
        "\n",
        "# Read and preprocess the uploaded image\n",
        "file_name = list(uploaded.keys())[0]\n",
        "img = cv2.imread(file_name, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "normalized_img = img / 255.0\n",
        "\n",
        "# Resize the image to match the input shape of the model\n",
        "normalized_img = cv2.resize(normalized_img, (48, 48))\n",
        "\n",
        "# Reshape the image to match the input shape of the model\n",
        "input_image = normalized_img.reshape(1, 48, 48, 1)\n",
        "\n",
        "# Make predictions using the model\n",
        "predictions = model.predict(input_image)\n",
        "emotion_label = np.argmax(predictions)\n",
        "predicted_emotion = emotion_mapping[emotion_label]\n",
        "\n",
        "print(f'Predicted Emotion: {predicted_emotion}')\n",
        "\n"
      ],
      "metadata": {
        "id": "wG0WZij68Opx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get emotion labels and corresponding probabilities\n",
        "emotion_labels = list(emotion_mapping.values())\n",
        "probabilities = predictions.flatten()\n",
        "\n",
        "# Plot the bar graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(emotion_labels, probabilities, color='blue')\n",
        "plt.xlabel('Emotion')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Predicted Emotion Probabilities')\n",
        "plt.ylim([0, 1])  # Set y-axis range between 0 and 1 for probability interpretation\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gviHNNrt8Otz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the pre-trained emotion detection model\n",
        "model = load_model('emotion_detection_model.h5')\n",
        "\n"
      ],
      "metadata": {
        "id": "PL2T_fDplUSC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}